{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URP08ZUq8lfh",
        "outputId": "1ee33e78-aa6f-400b-da76-02b9393cde61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "training_path = '/content/gdrive/My Drive/reinforcement/train.xlsx'\n",
        "validation_path = '/content/gdrive/My Drive/reinforcement/validate.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "seI0eDbu609y",
        "outputId": "121f5322-bd95-45ba-dbdc-5c3205f12b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install argparse\n",
        "!pip install gym\n",
        "!pip install pandas\n",
        "!pip install optuna\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gwLju8GV5860"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gym\n",
        "import pandas as pd\n",
        "import optuna\n",
        "from scipy.signal import find_peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ilYNsgQo6P73"
      },
      "outputs": [],
      "source": [
        "class Electric_Car(gym.Env):\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "\n",
        "        # Define a continuous action space, -1 to 1. (You can discretize this later!)\n",
        "        self.continuous_action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
        "        self.state = np.empty(7)\n",
        "\n",
        "        # Define the test data\n",
        "        self.test_data = pd.read_excel(file_path)\n",
        "        self.price_values = self.test_data.iloc[:, 1:25].to_numpy()\n",
        "        self.timestamps = self.test_data['PRICES']\n",
        "\n",
        "        # Battery characteristics\n",
        "        self.battery_capacity = 50                      # kWh\n",
        "        self.max_power = 25/0.9                         # kW\n",
        "        self.charge_efficiency = 0.9                    # -\n",
        "        self.discharge_efficiency = 0.9                 # -\n",
        "        self.battery_level = self.battery_capacity/2    # kWh (start at 50%)\n",
        "        self.minimum_morning_level = 20                 # kWh\n",
        "        self.car_use_consumption = 20                   # kWh\n",
        "\n",
        "        # Time Tracking\n",
        "        self.counter = 0\n",
        "        self.hour = 1\n",
        "        self.day = 1\n",
        "        self.car_is_available = True\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        action = np.squeeze(action)      # Remove the extra dimension # NOTE: wtf zit dit erin??\n",
        "\n",
        "        # Calculate if, at 7am and after the chosen action, the battery level will be below the minimum morning level:\n",
        "        if self.hour == 7:\n",
        "            if action > 0 and (self.battery_level < self.minimum_morning_level):\n",
        "                if (self.battery_level + action*self.max_power*self.charge_efficiency) < self.minimum_morning_level:     # If the chosen action will not charge the battery to 20kWh\n",
        "                    action = (self.minimum_morning_level - self.battery_level)/(self.max_power*self.charge_efficiency)  # Charge until 20kWh\n",
        "            elif action < 0:\n",
        "                if (self.battery_level + action*self.max_power) < self.minimum_morning_level:\n",
        "                    if self.battery_level < self.minimum_morning_level:                                                    # If the level was lower than 20kWh, charge until 20kWh\n",
        "                        action = (self.minimum_morning_level - self.battery_level)/(self.max_power*self.charge_efficiency) # Charge until 20kWh\n",
        "                    elif self.battery_level >= self.minimum_morning_level:                                                 # If the level was higher than 20kWh, discharge until 20kWh\n",
        "                        action = (self.minimum_morning_level - self.battery_level)/(self.max_power)                        # Discharge until 20kWh\n",
        "            elif action == 0:\n",
        "                if self.battery_level < self.minimum_morning_level:\n",
        "                    action = (self.minimum_morning_level - self.battery_level)/(self.max_power*self.charge_efficiency)\n",
        "\n",
        "        # There is a 50% chance that the car is unavailable from 8am to 6pm\n",
        "        if self.hour == 8:\n",
        "            self.car_is_available = np.random.choice([True, False])\n",
        "            if not self.car_is_available:\n",
        "                self.battery_level -= self.car_use_consumption\n",
        "        if self.hour == 18:\n",
        "            self.car_is_available = True\n",
        "        if not self.car_is_available:\n",
        "            action = 0\n",
        "\n",
        "        # Calculate the costs and battery level when charging (action >0)\n",
        "        if (action >0) and (self.battery_level <= self.battery_capacity):\n",
        "            if (self.battery_level + action*self.max_power*self.charge_efficiency) > self.battery_capacity:\n",
        "                action = (self.battery_capacity - self.battery_level)/(self.max_power*self.charge_efficiency)\n",
        "            charged_electricity_kW = action * self.max_power\n",
        "            charged_electricity_costs = charged_electricity_kW * self.price_values[self.day-1][self.hour-1] * 2 * 1e-3\n",
        "            reward = -charged_electricity_costs\n",
        "            self.battery_level += charged_electricity_kW*self.charge_efficiency\n",
        "\n",
        "        # Calculate the profits and battery level when discharging (action <0)\n",
        "        elif (action < 0) and (self.battery_level >= 0):\n",
        "            if (self.battery_level + action*self.max_power) < 0:\n",
        "                action = -self.battery_level/(self.max_power)\n",
        "            discharged_electricity_kWh = action * self.max_power           # Negative discharge value\n",
        "            discharged_electricity_profits = abs(discharged_electricity_kWh) * self.discharge_efficiency * self.price_values[self.day-1][self.hour-1] * 1e-3\n",
        "            reward = discharged_electricity_profits\n",
        "            self.battery_level += discharged_electricity_kWh\n",
        "            # Some small numerical errors causing the battery level to be 1e-14 to 1e-17 under 0 :\n",
        "            if self.battery_level < 0:\n",
        "                self.battery_level = 0\n",
        "\n",
        "        else:\n",
        "            reward = 0\n",
        "\n",
        "        self.counter += 1    # Increase the counter\n",
        "        self.hour += 1       # Increase the hour\n",
        "\n",
        "        if self.counter % 24 == 0:  # If the counter is a multiple of 24, increase the day, reset hour to first hour\n",
        "            self.day += 1\n",
        "            self.hour = 1\n",
        "\n",
        "        terminated = self.counter == len(self.price_values.flatten()) - 1   # If the counter is equal to the number of hours in the test data, terminate the episode\n",
        "        truncated = False\n",
        "\n",
        "        info = action                                                 # The final action taken after all constraints!\n",
        "        self.state = self.observation()                               # Update the state\n",
        "\n",
        "        return self.state, reward, terminated, truncated, info\n",
        "\n",
        "    def observation(self):  # Returns the current state\n",
        "        battery_level = self.battery_level\n",
        "        price = self.price_values[self.day -1][self.hour-1]\n",
        "        hour = self.hour\n",
        "        day_of_week = self.timestamps[self.day -1].dayofweek  # Monday = 0, Sunday = 6\n",
        "        day_of_year = self.timestamps[self.day -1].dayofyear  # January 1st = 1, December 31st = 365\n",
        "        month = self.timestamps[self.day -1].month            # January = 1, December = 12\n",
        "        year = self.timestamps[self.day -1].year\n",
        "        self.state = np.array([battery_level, price, int(hour), int(day_of_week), int(day_of_year), int(month), int(year)])\n",
        "\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "I-IuVXqgyHh8"
      },
      "outputs": [],
      "source": [
        "def price_peaks(prices_data, hour, day):\n",
        "    peak = False\n",
        "    trough = False\n",
        "\n",
        "    if day > 2:\n",
        "\n",
        "        # prices of last week and today\n",
        "        prices_ = prices_data[day-2:day, :]\n",
        "\n",
        "        # remove today's prices after the current hour\n",
        "        prices_[-1, hour:] = np.nan\n",
        "\n",
        "        # remove hours before current hour of first day\n",
        "        prices_[0, :hour] = np.nan\n",
        "\n",
        "        # drop nan values\n",
        "        prices_ = prices_[~np.isnan(prices_)]\n",
        "\n",
        "        # duplicate prices\n",
        "        prices_ = np.concatenate((prices_, prices_))\n",
        "\n",
        "\n",
        "        # get index of peaks and troughs\n",
        "        peaks, _ = find_peaks(prices_, distance=12)\n",
        "        troughs, _ = find_peaks(-prices_, distance=12)\n",
        "\n",
        "        if hour in peaks:\n",
        "            peak = True\n",
        "\n",
        "        if hour in troughs:\n",
        "            trough = True\n",
        "\n",
        "    return peak, trough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA-gmbZrWlpT",
        "outputId": "2fdf806c-0814-410c-fde8-fc74b75952a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "env = Electric_Car('train.xlsx')\n",
        "prices = env.price_values\n",
        "prices = prices[prices < 300]\n",
        "quantiles = np.arange(0, 1, 0.1)\n",
        "quantile_values = np.quantile(prices, quantiles)\n",
        "\n",
        "def bin_price(price, prices, quantile_values = quantile_values):\n",
        "\n",
        "  # bin price into based on quantiles\n",
        "  if price > quantile_values[-1]:\n",
        "      price = len(quantile_values)\n",
        "\n",
        "  else:\n",
        "      for i in range(len(quantile_values)):\n",
        "          if price < quantile_values[i]:\n",
        "              price = i\n",
        "              break\n",
        "  return price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kns2vS95yfNS"
      },
      "outputs": [],
      "source": [
        "def get_state(observation, price_values_):\n",
        "    battery_level, price, hour_of_day, day_of_week, day_of_year, month_of_year, year = observation\n",
        "    hour_of_day = hour_of_day - 1 # Hour of day is between 1 and 24, but the Q-table is between 0 and 23\n",
        "    month_of_year = month_of_year - 1 # Month of year is between 1 and 12, but the Q-table is between 0 and 11\n",
        "\n",
        "    if day_of_week == 5 or day_of_week == 6:\n",
        "        weekend = 0 # True\n",
        "    else:\n",
        "        weekend = 1 # False\n",
        "\n",
        "    month_of_year, weekend, hour_of_day= int(month_of_year), int(weekend), int(hour_of_day)\n",
        "\n",
        "    season = 0\n",
        "    if month_of_year == 11 or month_of_year == 0 or month_of_year == 1:\n",
        "        season = 0\n",
        "    elif month_of_year == 2 or month_of_year == 3 or month_of_year == 4:\n",
        "        season = 1\n",
        "    elif month_of_year == 5 or month_of_year == 6 or month_of_year == 7:\n",
        "        season = 2\n",
        "    elif month_of_year == 8 or month_of_year == 9 or month_of_year == 10:\n",
        "        season = 3\n",
        "\n",
        "    # bin battery level into 4 bins\n",
        "    if battery_level < 12.5:\n",
        "        battery_level = 0\n",
        "    elif battery_level < 25:\n",
        "        battery_level = 1\n",
        "    elif battery_level < 37.5:\n",
        "        battery_level = 2\n",
        "    else:\n",
        "        battery_level = 3\n",
        "\n",
        "    price = bin_price(price, price_values_)\n",
        "\n",
        "    current_state = [hour_of_day, weekend, season, battery_level, price]\n",
        "\n",
        "    return current_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "q5TFKno15q2b"
      },
      "outputs": [],
      "source": [
        "class QLearningAgent():\n",
        "    def __init__(self):\n",
        "        self.action_space = [-1, 0, 1]\n",
        "        self.learning_rate = 0.1\n",
        "        self.discount_factor = 0.9\n",
        "        self.epsilon = 0.1\n",
        "        self.q_table = {}\n",
        "    \n",
        "    def get_q_value(self, state, action):\n",
        "        state_action = tuple(state + [action])\n",
        "        return self.q_table.get(state_action, 0.0)\n",
        "\n",
        "    def update_q_value(self, state, action, new_q_value):\n",
        "        state_action = tuple(state + [action])\n",
        "        self.q_table[state_action] = new_q_value\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        actions = self.action_space\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(actions)\n",
        "        else:\n",
        "            q_values = [self.get_q_value(state, a) for a in actions]\n",
        "            index = np.argmax(q_values)\n",
        "            return actions[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4JpfICaf5q2k"
      },
      "outputs": [],
      "source": [
        "def run_simulation(n_simulations = 10, lr=0.01, discount=0.9, e=0.4, train = True, print_ = True, decay = True, end_e = 0.01, increase = True, end_d = 0.99):\n",
        "\n",
        "    ql_agent = QLearningAgent()\n",
        "\n",
        "    if train == True:\n",
        "        file_path = 'train.xlsx'\n",
        "\n",
        "    # if validation data, use the Q-learning agent you trained in the previous step\n",
        "    else:\n",
        "        file_path = 'validate.xlsx'\n",
        "\n",
        "        # load the Q-table from the previous step\n",
        "        ql_agent.q_table = np.load('q_table.npy', allow_pickle=True).item()\n",
        "\n",
        "    # Use (hyper)parameters of your choice\n",
        "    ql_agent.learning_rate = lr\n",
        "    ql_agent.discount_factor = discount\n",
        "    ql_agent.epsilon = e\n",
        "    epsilon_decay = (e - end_e) / n_simulations \n",
        "    discount_increase = (end_d - discount) / n_simulations\n",
        "    bankaccounts = []\n",
        "\n",
        "    for simulation in range(n_simulations):\n",
        "        if decay:\n",
        "            ql_agent.epsilon = max(end_e, ql_agent.epsilon - epsilon_decay)\n",
        "        if increase:\n",
        "            ql_agent.discount_factor = min(end_d, ql_agent.discount_factor + discount_increase)\n",
        "        if print_:\n",
        "            if simulation % 10 == 0:\n",
        "                print('Simulation: ', simulation, 'discount: ', ql_agent.discount_factor, 'epsilon: ', ql_agent.epsilon)\n",
        "\n",
        "        env = Electric_Car(file_path)\n",
        "        bankaccount = 0\n",
        "        observation = env.observation()\n",
        "\n",
        "        # get the current states\n",
        "        current_state = get_state(observation, env.price_values)\n",
        "\n",
        "        for i in range(730 * 24 - 1):  # Loop through 2 years -> 730 days * 24 hours\n",
        "\n",
        "            # Choose an action based on the observation using your Q-learning agent\n",
        "            action = int(ql_agent.choose_action(current_state))\n",
        "            next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "            # if action != info:\n",
        "            #     if info < 0:\n",
        "            #         action = -1\n",
        "            #     elif info > 0\n",
        "            #         action = 1\n",
        "            #     else:\n",
        "            #         action = 0\n",
        "\n",
        "            # save reward before shaping\n",
        "            reward_ = reward\n",
        "            \n",
        "            # get peaks and troughs\n",
        "            peak, trough = price_peaks(env.price_values, env.hour-1, env.day-1)\n",
        "\n",
        "            # reward factor\n",
        "            if peak and action < 0: # if peak and discharge (getting a positive reward)\n",
        "                reward *= 2 # multiply by 1.5\n",
        "\n",
        "            elif trough and action < 0: # if trough and discharge (getting a positive reward)\n",
        "                reward *= -1 # flip to negative reward\n",
        "\n",
        "            if trough and action > 0: # if trough and charge (getting a negative reward)\n",
        "                reward *= -1 # flip to positive reward\n",
        "\n",
        "            elif peak and action > 0: # if peak and charge (getting a negative reward)\n",
        "                reward *= 2 # make more negative\n",
        "\n",
        "            # Get next states\n",
        "            next_state = get_state(next_observation, env.price_values)\n",
        "\n",
        "            # Update Q-value using Q-learning update rule\n",
        "            next_max_q_value = max([ql_agent.get_q_value(next_state, a) for a in [-1, 0, 1]])\n",
        "            current_q_value = ql_agent.get_q_value(current_state, action)\n",
        "            new_q_value = current_q_value + ql_agent.learning_rate * (reward + ql_agent.discount_factor * next_max_q_value - current_q_value)\n",
        "            ql_agent.update_q_value(current_state, action, new_q_value)\n",
        "\n",
        "            bankaccount += reward_\n",
        "            observation = next_observation\n",
        "            current_state = next_state\n",
        "\n",
        "            # If the episode is terminated, reset the environment and break the loop\n",
        "            if i == (729*24 - 2):\n",
        "                bankaccounts.append(bankaccount) # Save the cumulative reward of the last day of the simulation\n",
        "                break\n",
        "\n",
        "    if train:\n",
        "        plt.plot(bankaccounts) # Plot the cumulative reward per simulation\n",
        "        plt.xlabel('Simulation')\n",
        "        plt.ylabel('Cumulative reward (â‚¬)')\n",
        "        plt.show()\n",
        "\n",
        "        # save the Q-table\n",
        "        np.save('q_table.npy', ql_agent.q_table)\n",
        "\n",
        "        # Return the bankaccount of the last simulation\n",
        "        return bankaccount\n",
        "\n",
        "    # If validation data, return the average cumulative reward of all simulations\n",
        "    # for stochasticity reasons\n",
        "    else:\n",
        "        return np.mean(bankaccounts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W68Lpwn7zFLG",
        "outputId": "89083610-9db8-4de0-c491-16ee876b6963"
      },
      "outputs": [],
      "source": [
        "run_simulation(n_simulations = 150, lr=0.01, discount=0.9, e=0.4, train = True, increase = True, end_d = 0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P2e0eNafpOo_",
        "outputId": "4b8b070a-1e69-49b7-e555-37e226b45ef2"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETER OPTIMIZATION\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_uniform('lr', 0.01, 0.1)\n",
        "    discount = trial.suggest_uniform('discount', 0.7, 0.99)\n",
        "    e = trial.suggest_uniform('e', 0.1, 0.3)\n",
        "\n",
        "    # training data for q_table\n",
        "    run_simulation(n_simulations = 500, lr=lr, discount=discount, e=e, train = True, print_ = False)\n",
        "\n",
        "    # validation data (run 3 times to reduce stochasticity)\n",
        "    validation_score = run_simulation(n_simulations = 3, lr=lr, discount=discount, e=e, train = False, print_ = False)\n",
        "\n",
        "    return validation_score\n",
        "\n",
        "def call_back(study, trial):\n",
        "    if study.best_trial == trial:\n",
        "        print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n",
        "\n",
        "        with open('best_params.txt', 'w') as f:\n",
        "            f.write(str(study.best_trial.params))\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100, callbacks=[call_back])\n",
        "\n",
        "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB1JTaoK43G0"
      },
      "outputs": [],
      "source": [
        "# save the best parameters to a file\n",
        "best_params = study.best_trial.params\n",
        "with open('/content/gdrive/My Drive/reinforcement/best_params.txt', 'w') as f:\n",
        "    f.write(str(best_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wkftGTapXVW"
      },
      "outputs": [],
      "source": [
        "# EXTENSIVE TRAINING\n",
        "training_score = run_simulation(n_simulations = 1000, lr=study.best_trial.params['lr'], discount=study.best_trial.params['discount'], e=study.best_trial.params['e'], train = True)\n",
        "print('Training score: ', training_score)\n",
        "\n",
        "# VALIDATION\n",
        "validation_score = run_simulation(n_simulations = 10, lr=study.best_trial.params['lr'], discount=study.best_trial.params['discount'], e=study.best_trial.params['e'], train = False)\n",
        "print('Validation score: ', validation_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
